# LLM Explainer Project

## Overview

The web application allows participants to interact with an LLM, asking questions and generating plots about a dataset. The goal is to help users better understand the dataset and the LLM's assistant in ML models.

## Prerequisites

Before running the project, ensure you have the following installed:

- Python 3.x
- Node.js and npm

## Setup Instructions

### Backend Setup

1. **Navigate to the backend directory:**
   ```bash
   cd backend
2. **Run the Backend**
   ```bash
   python3 app.py

### Frontend Setup
1. **In a new terminal, navigate to the frontend directory:**
   ```bash
   cd frontend
2. **Run the Frontend**
   ```bash
   npm install
   npm start
### Usage
Once both the backend and frontend are running, participants can access the application by navigating to http://localhost:3000 in their web browser.
### Features
**Ask Questions**: Participants can ask the LLM questions about the dataset to gain insights and clarifications.<br>
**Generate Plots**: The interface allows users to generate visualizations of the dataset, helping to contextualize and better understand the data.

## Authors
This web interface was fully created and is maintained by Jian Yun Zhuang. The project is ongoing and led by Jessica Bo, under the supervision of Professor Ashton Anderson at the University of Toronto.
